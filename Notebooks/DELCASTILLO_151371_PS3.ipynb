{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 3 CS129.18\n",
    "\n",
    "The following problem set will revolve around the Enron Emails dataset.\n",
    "The dataset `data/enron-data/` directory has 6 files. The objective is to build a classifier for whether email is spam or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "\n",
    ">Spam or Ham?\n",
    "\n",
    "Using the lessons on Naive Bayes and TF-IDF, and the other resource notebooks, show the following in this Jupyter Notebook.\n",
    "\n",
    "Write your answers down as Markdown cells or comments in the code.\n",
    "\n",
    "**Using Enron 1 and 2**\n",
    "\n",
    "1. How many Spam Emails are there? ( 1 pt )\n",
    "\n",
    "2. Structure the email data from the 3 directories into 1 dataframe with columns: Status, Subject, Body ( 7 pts )\n",
    "\n",
    "3. Build a Naive Bayes classifier to classify whether emails are spam or not. ( 3 pts )\n",
    "\n",
    "4. What is the longest ham email? ( 1 pt )\n",
    "\n",
    "5. What is the accuracy of your model?( 1 pt )\n",
    "\n",
    "6. Include the Subject in the analysis of the emails, does the accuracy/performance of the model increase? (7 pts)\n",
    "\n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "\n",
    "Bonus : Answer questions 1-6 using Enron 1,2, and 3. (5 pts)\n",
    "\n",
    "----\n",
    "\n",
    "**Submit this file on Moodle on the submission link I will provide. This is due October 18 12nn.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/enron-data/enron1 ['ham', 'spam'] 2\n",
      "data/enron-data/enron1\\ham [] 3672\n",
      "data/enron-data/enron1\\spam [] 1500\n",
      "data/enron-data/enron2 ['ham', 'spam'] 1\n",
      "data/enron-data/enron2\\ham [] 4361\n",
      "data/enron-data/enron2\\spam [] 1496\n",
      "data/enron-data/enron3 ['ham', 'spam'] 1\n",
      "data/enron-data/enron3\\ham [] 4012\n",
      "data/enron-data/enron3\\spam [] 1500\n"
     ]
    }
   ],
   "source": [
    "rootdirs = [\n",
    "    \"data/enron-data/enron1\",\n",
    "    \"data/enron-data/enron2\",\n",
    "    \"data/enron-data/enron3\",\n",
    "#     \"data/enron-data/enron4\",\n",
    "#     \"data/enron-data/enron5\",\n",
    "#     \"data/enron-data/enron6\",\n",
    "]\n",
    "\n",
    "# Loop through all the directories, sub directories and files in the above folder, and print them.\n",
    "for rootdir in rootdirs:\n",
    "    for directories, subdirs, files in os.walk(rootdir):\n",
    "        print(directories, subdirs, len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12045\n",
      "4496\n"
     ]
    }
   ],
   "source": [
    "ham_list = []\n",
    "spam_list = []\n",
    "\n",
    "# Same as before, but this time, read the files, and append them to the ham and spam list\n",
    "for rootdir in rootdirs:\n",
    "    for directories, subdirs, files in os.walk(rootdir):\n",
    "        if (os.path.split(directories)[1]  == 'ham'):\n",
    "            for filename in files:      \n",
    "                with open(os.path.join(directories, filename), encoding=\"latin-1\") as f:\n",
    "                    data = f.read()\n",
    "                    ham_list.append(data)\n",
    "\n",
    "        if (os.path.split(directories)[1]  == 'spam'):\n",
    "            for filename in files:\n",
    "                with open(os.path.join(directories, filename), encoding=\"latin-1\") as f:\n",
    "                    data = f.read()\n",
    "                    spam_list.append(data)\n",
    "\n",
    "\n",
    "print(len(ham_list))\n",
    "print(len(spam_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4496 spam emails\n"
     ]
    }
   ],
   "source": [
    "# 1. Number of Spam Emails\n",
    "print('There are {spam} spam emails'.format(spam=len(spam_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>raw</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>christmas tree farm pictures</td>\n",
       "      <td></td>\n",
       "      <td>christmas tree farm pictures</td>\n",
       "      <td>Subject: christmas tree farm pictures\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>vastar resources   inc</td>\n",
       "      <td>gary   production from the high island larger ...</td>\n",
       "      <td>vastar resources   inc   gary   production fro...</td>\n",
       "      <td>Subject: vastar resources , inc .\\ngary , prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>calpine daily gas nomination</td>\n",
       "      <td>calpine daily gas nomination 1   doc</td>\n",
       "      <td>calpine daily gas nomination   calpine daily g...</td>\n",
       "      <td>Subject: calpine daily gas nomination\\n- calpi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>issue</td>\n",
       "      <td>fyi   see note below   already done   stella  ...</td>\n",
       "      <td>issue fyi   see note below   already done   st...</td>\n",
       "      <td>Subject: re : issue\\nfyi - see note below - al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>meter 7268 nov allocation</td>\n",
       "      <td>fyi                                           ...</td>\n",
       "      <td>meter 7268 nov allocation fyi                 ...</td>\n",
       "      <td>Subject: meter 7268 nov allocation\\nfyi .\\n- -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  status                       subject  \\\n",
       "0    ham  christmas tree farm pictures   \n",
       "1    ham      vastar resources   inc     \n",
       "2    ham  calpine daily gas nomination   \n",
       "3    ham                         issue   \n",
       "4    ham     meter 7268 nov allocation   \n",
       "\n",
       "                                                body  \\\n",
       "0                                                      \n",
       "1  gary   production from the high island larger ...   \n",
       "2               calpine daily gas nomination 1   doc   \n",
       "3  fyi   see note below   already done   stella  ...   \n",
       "4  fyi                                           ...   \n",
       "\n",
       "                                                 raw  \\\n",
       "0                      christmas tree farm pictures    \n",
       "1  vastar resources   inc   gary   production fro...   \n",
       "2  calpine daily gas nomination   calpine daily g...   \n",
       "3  issue fyi   see note below   already done   st...   \n",
       "4  meter 7268 nov allocation fyi                 ...   \n",
       "\n",
       "                                            original  \n",
       "0            Subject: christmas tree farm pictures\\n  \n",
       "1  Subject: vastar resources , inc .\\ngary , prod...  \n",
       "2  Subject: calpine daily gas nomination\\n- calpi...  \n",
       "3  Subject: re : issue\\nfyi - see note below - al...  \n",
       "4  Subject: meter 7268 nov allocation\\nfyi .\\n- -...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. Structure Data\n",
    "data = {\n",
    "    'status': [],\n",
    "    'subject': [],\n",
    "    'body': [],\n",
    "    'raw': [],\n",
    "    'original': [],\n",
    "}\n",
    "\n",
    "import re\n",
    "\n",
    "def mike_clean(string):\n",
    "    return re.sub(r\"[^a-zA-Z0-9]\", r\" \", string.strip())\n",
    "\n",
    "def mike_append(status, the_list):\n",
    "    for string in the_list:\n",
    "        # removes Subject: fw: or re:\n",
    "        subject = mike_clean(re.sub(r\"^Subject:(.{0,4}\\:){0,1}\", r\"\", string.split('\\n', 1)[0]))\n",
    "        body = mike_clean(''.join(string.split('\\n', 1)[1:]))\n",
    "        data['status'].append(status)\n",
    "        data['subject'].append(subject)\n",
    "        data['body'].append(body)\n",
    "        data['raw'].append(subject + \" \" + body)\n",
    "        data['original'].append(string)\n",
    "\n",
    "mike_append(\"ham\", ham_list)\n",
    "mike_append(\"spam\", spam_list)\n",
    "\n",
    "df = pd.DataFrame(data=data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16541"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split\n",
      "vectorize\n",
      "indexed\n",
      "classifier\n",
      "(5459, 55075)\n",
      "Accuracy: 93.53 percent\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(data[\"body\"], data[\"status\"], test_size=0.33, random_state=2574)\n",
    "print(\"split\")\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_train_x = vectorizer.fit_transform(train_x)\n",
    "print(\"vectorize\")\n",
    "\n",
    "index_value={i[1]:i[0] for i in vectorizer.vocabulary_.items()}\n",
    "fully_indexed = []\n",
    "for row in tfidf_train_x:\n",
    "    fully_indexed.append({index_value[column]:value for (column,value) in zip(row.indices,row.data)})\n",
    "print(\"indexed\")\n",
    "\n",
    "# 3. NB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(tfidf_train_x.toarray(), train_y)\n",
    "print(\"classifier\")\n",
    "\n",
    "#5. Accuracy\n",
    "\n",
    "tfidf_test_x = vectorizer.fit_transform(test_x)\n",
    "print(tfidf_test_x.shape)\n",
    "scores = cross_val_score(classifier, tfidf_test_x.toarray(), test_y, cv=5)\n",
    "acc = scores.mean()\n",
    "print(\"Accuracy: %0.2f percent\" % (acc *100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest ham email is 228377 characters long.\n"
     ]
    }
   ],
   "source": [
    "# 4. Longest Ham Email\n",
    "\n",
    "ham_list.sort(key=len)\n",
    "longest_email = ham_list[len(ham_list) - 1]\n",
    "\n",
    "print('The longest ham email is {len} characters long.'.format(len=len(longest_email),email=longest_email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4136, 84581)\n",
      "Accuracy: 93.33 percent\n"
     ]
    }
   ],
   "source": [
    "# 6. With Subject\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(data[\"raw\"], data[\"status\"])\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_train_x = vectorizer.fit_transform(train_x)\n",
    "\n",
    "index_value={i[1]:i[0] for i in vectorizer.vocabulary_.items()}\n",
    "fully_indexed = []\n",
    "for row in tfidf_train_x:\n",
    "    fully_indexed.append({index_value[column]:value for (column,value) in zip(row.indices,row.data)})\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(tfidf_train_x.toarray(), train_y)\n",
    "\n",
    "tfidf_test_x = vectorizer.transform(test_x)\n",
    "print(tfidf_test_x.shape)\n",
    "scores = cross_val_score(classifier, tfidf_test_x.toarray(), test_y, cv=5)\n",
    "acc = scores.mean()\n",
    "print(\"Accuracy: %0.2f percent\" % (acc *100))\n",
    "\n",
    "# Answer: Parsing the raw body including the subject gives \n",
    "# the model more text to work with. While the improvement \n",
    "# may be little, there certainly is one. Adding the subject \n",
    "# improves its accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
